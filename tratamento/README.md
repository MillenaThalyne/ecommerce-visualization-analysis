# Tratamento de Dados üé≤
- Para essa primeira etapa do projeto, irei realizar o tratamento dos dados focado em: Remo√ß√£o de algumas colunas, tratamento de tipos, tratamento de nulos e
tratamento de duplicados. A seguir irei detalhar melhor as abordagens que tomei e o porqu√™ delas;
- Qualquer sugest√£o para melhoria de qualquer parte desse projeto, pode entrar em contato comigo pelo LinkedIn ou email (link no perfil).
# Bibliotecas Utilizadas nessa Etapa üìã
> Pandas <br>
> Matplotlib <br>
> Seaborn
# Constru√ß√£o dos Tratamentos üîß
## Remo√ß√£o de Colunas
- Nessa parte do projeto, notei que existia uma coluna de √≠ndice desnecess√°ria, pois o Pandas cria, assim que l√™ seus arquivos, uma coluna exatamente igual a essa;
- Tamb√©m exclui as colunas do MinMaxScaler para poder refaz√™-las na etapa de prepara√ß√£o, pois, como irei fazer diversas altera√ß√µes nas colunas originais, estas ser√£o inviesadas;
- Por conta desse ponto, decidi por excluir essa coluna, que foi relacionada ao DataFrame ‚Äòdf_eco‚Äô para distin√ß√£o do original.
## Tratamento de Tipos
### Coluna 'Qtd_Vendidos'
- Minha ideia de tratamento para essa coluna foi transformar em inteiro para poder fazer an√°lises futuras;
- Para isso, removi o '+', substitui 'mil' por '000' e 'Nenhum' por '0', para depois tranform√°-los em inteiro; 
- Quando terminei meu trabalho, notei que j√° existia uma coluna com essas informa√ß√µes, a 'Qtd_Vendidos_Cod', por√©m com o tipo *float*. Dessa forma, decidi por excluir essa coluna l√° cima tamb√©m para deixar somente a que eu havia tratado.
## Tratamento de Nulos
- Logo de cara, vemos uma quantidade bem grande de dados nulos em diversas colunas, sendo sua maior quantidade presente no campo ‚ÄòDesconto‚Äô, com 1325 registros nulos;
- Como cada um dos elementos tem sua import√¢ncia, n√£o posso simplesmente excluir tudo. Por isso, farei o tratamento de acordo com o contexto do campo. Por exemplo, em Desconto, faria sentido que os dados nulos presentes nele seja porque n√£o houve desconto. Nesse caso, se o tipo dele √© float, seria interessante substituir os dados nulos por 0.0, o que caracterizaria uma n√£o inclus√£o de desconto naquela compra;
- Cada campo ter√° seu tratamento espec√≠fico, por isso, em cada etapa irei detalhar melhor a abordagem que tomei.
### Tratamento de 'Nota'
- Meu primeiro pensamento ao ver dados nulos em notas √© que poderia ser 0, mas n√£o, isso seria dizer que as pessoas n√£o gostaram nem um pouco do produto e n√£o sabemos nisso. Tamb√©m pensei em preencher com a m√©dia, mas tamb√©m seria impreciso, pois n√£o temos como saber exatamente o porqu√™ de n√£o terem preenchido esse campo na hora da avalia√ß√£o e, por isso, seria uma presun√ß√£o;
-  Por isso, a abordagem que pensei nesse caso seria preencher esses registros nulos pela mediana deles, pois exclu√≠-los reduziria drasticamente nossos dados. Ent√£o, como esses dados s√£o importantes, utilizar a mediana deles para suprir essa falta seria uma abordagem interessante, uma vez que a quantidade de registros totais j√° √© bastante pequena e ainda teremos diversos tratamentos posteriores que o reduzir√£o ainda mais.
### Tratamento de 'N_Avalia√ß√µes'
- Nesse caso, eu posso crer que quando n√£o temos n√∫mero de avalia√ß√µes, quer dizer que ela √© igual a 0, ou seja, n√£o tem avalia√ß√µes desse produto;
- Ent√£o fica bem simples, pois pode-se somente substituir os valores nulos por 0 para informar isso.
### Tratamento de Desconto
- Como falei anteriormente, a aus√™ncia de registro nesse campo significaria que n√£o houve desconto, ou seja, desconto = 0.
### Tratamento de 'Material'
- Antes de verificar qual a melhor abordagem para os registros nulos nesse campo, eu verifiquei do que ele se trata, sendo a categoria do material daquele produto. Com isso, acredito que a aus√™ncia de um material seria, ent√£o, desconhecido ou indeterminado.
### Tratamento de 'G√™nero'
- Primeiro verifiquei qual os registros √∫nicos e notei que existia uma categoria ‚ÄòSem g√™nero‚Äô que se encaixaria nesse contexto. Por isso, fiz o tratamento de nulos substituindo para essa categoria porque esse campo possui uma porcentagem bem baixa de registros nulos (4%) e fazendo isso, n√£o influenciaria tanto, afinal, se n√£o tem registro de g√™nero, muito provavelmente ele n√£o √© necess√°rio para aquele contexto.
### Tratamento de 'Reviews'
- Pegando a l√≥gica de G√™nero, se n√£o existe registro de review, quer dizer que o cliente n√£o deixou um coment√°rio. Por isso, podemos substituir essa aus√™ncia por ‚ÄòSem coment√°rios‚Äô, por exemplo.
### Tratamento de 'Pre√ßo'
- Esse tratamento vai ser o mais complicado, pois todos os produtos deveriam ter pre√ßo. Ent√£o, se n√£o tem pre√ßo, o que aconteceu? Provavelmente foi erro de extra√ß√£o, mas n√£o podemos colocar ‚ÄòN√£o informado‚Äô por exemplo, porque esse campo √© do tipo *float* e esse tratamento iria ir contra isso. Tamb√©m n√£o podemos fazer uma aproxima√ß√£o (usando alguma medida estat√≠stica) dele, pois iria ser provavelmente diferente do pre√ßo real e esse campo √© muito importante. O que n√£o seria o caso se fosse a idade (e n√£o usar√≠amos esse campo pra an√°lise, por exemplo), mas o pre√ßo ser√° utilizado posteriormente, ent√£o provavelmente eu irei desconsiderar eles da minha an√°lise;
- E pensando sobre isso, se eu vou desconsiderar esses registros da minha an√°lise, n√£o seria melhor exclu√≠-los? Bom, ele representa 11% dos dados, o que √© mediano, mas, como falei, esses dados s√£o importantes e insubstitu√≠veis, portanto, √© uma abordagem interessante (se tiver uma sugest√£o melhor, eu adoraria ouvir!).
### Tratamento de 'Material_Freq'
- Esse campo representa a frequ√™ncia das categorias de Material nos dados. Ela tem a mesma porcentagem de dados nulos que Material, o que leva a crer que foi criada enquanto os dados de Material contia nulos. Com isso, eu vou excluir ele agora e refaz√™-lo na etapa de prepara√ß√£o.
## Tratamento de Duplicados
- Com esse tratamento, notamos que 201 registros foram exclu√≠dos por estarem duplicados. Como n√£o temos algum dado que necessariamente precisa ser √∫nico para ser v√°lido (como um registro de clientes por CPF), esse tratamento ser√° feito em toda base de dados e o Python ir√° fazer seu crit√©rio para duplicidade.
## Visualiza√ß√£o de Outliers (EXTRA)
- Pode-se visualizar as vari√°veis num√©ricas de Nota, N_Avalia√ß√µes, Desconto e Pre√ßo est√£o com bastante valores discrepantes;
- Por√©m isso √© o esperado, j√° que s√£o registro de produtos e alguns produtos podem ser mais populares que outros, e, por isso, terem uma nota maior, um desconto maior ou um pre√ßo maior. Por causa disso, n√£o irei fazer o tratamento dessas outliers, mas deixarei aqui a n√≠vel de conhecimento (e como exemplo de como fazer esse tipo de gr√°fico comparativo).
## Verificando Dados Tratados 
- Ao final de todo esse trabalho, obtemos as seguintes informa√ß√µes:
  - **Quantidade de Registros Originais**: 2199
  - **Quantidade de Registros com Tratamento**: 1763
  - **Quantidade de Colunas Originais**: 24
  - **Quantidade de Colunas com Tratamento**: 17
  - **Nomes das Colunas Usadas**:<br> ['T√≠tulo', 'Nota', 'N_Avalia√ß√µes', 'Desconto', 'Marca', 'Material', 'G√™nero', 'Temporada', 'Review1', 'Review2', 'Review3', 'Qtd_Vendidos', 'Pre√ßo', 'Marca_Cod', 'Material_Cod', 'Temporada_Cod', 'Marca_Freq']
  - **Quantidade de Nulos**: 0 (por coluna)
  - **Quantidade de Duplicados**: 0
- Esses dados foram salvos no arquivo 'ecommerce_tratado.csv', dispon√≠vel na pasta 'dados'. 
